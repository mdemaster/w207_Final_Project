{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4040, 32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "pd_train = pd.read_json('https://raw.githubusercontent.com/mdemaster/w207_Final_Project/master/train.json', orient='columns')\n",
    "pd_test = pd.read_json('https://raw.githubusercontent.com/mdemaster/w207_Final_Project/master/test.json', orient='columns')\n",
    "\n",
    "np_test = np.array(pd_test)\n",
    "np_train = np.array(pd_train)\n",
    "\n",
    "print np_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (4040,)\n",
      "label shape: (4040,)\n",
      "How has my week been? Well I got paid on Thursday and after paying the mortgage and unexpected meds I have about $15-20 to last me the next 2 weeks after it all clears the bank.\n",
      "\n",
      "So I am sitting here at work dreading going home to another bowl of ramen or a PB&amp;J. And while I don't really NEED a pizza tonight it would be nice.\n",
      "\n",
      "I'm in West Texas btw.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = np_train[:,7]\n",
    "Y = np_train[:,22]\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print 'data shape: ', X.shape\n",
    "print 'label shape:', Y.shape\n",
    "\n",
    "l=len(X)\n",
    "train_data, train_labels = X[:l/2], Y[:l/2]\n",
    "dev_data, dev_labels = X[l/2:(3*l)/4], Y[l/2:(3*l)/4]\n",
    "test_data, test_labels = X[(3*l)/4:], Y[(3*l)/4:]\n",
    "\n",
    "print train_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Scores...\n",
      "Naive Bayes Baseline:\n",
      "Best Alpha = 10.0  accuracy: 0.759405940594\n",
      "\n",
      "Logistic Regression Baseline:\n",
      "Best C = 0.0001  accuracy: 0.759405940594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run initial vectorizer and fit_transform on train_data and find vocab size from shape attribute.\n",
    "vect=CountVectorizer()\n",
    "data=vect.fit_transform(train_data).toarray()\n",
    "devdata=vect.transform(dev_data).toarray()\n",
    "\n",
    "\n",
    "#Use np.where to binarize train and dev set where values above and below 0.5.\n",
    "b=train_labels\n",
    "trainlabels=np.where(b==True, 1, 0)\n",
    "\n",
    "bl=dev_labels\n",
    "devlabels=np.where(bl==True, 1, 0)\n",
    "\n",
    "b2=test_labels\n",
    "testlabels=np.where(b2==True, 1, 0)\n",
    "\n",
    "categories = ['Didn\\'t get pizza','Got Pizza']\n",
    "\n",
    "print 'Baseline Scores...'\n",
    "#Run MultinomialNB Classifier\n",
    "# mnb_clf = Pipeline([('vect', CountVectorizer()), ('mnclf',MultinomialNB(alpha=0.01))])\n",
    "# mnb_clf = mnb_clf.fit(train_data, trainlabels)\n",
    "# pred = mnb_clf.predict(dev_data)\n",
    "# score1=metrics.accuracy_score(devlabels,pred)\n",
    "# print 'Naive Bayes Score:',score1\n",
    "best_nb = []\n",
    "alphas = [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "for k in range(len(alphas)):\n",
    "    mnb_clf = Pipeline([('vect', CountVectorizer()), ('mnclf', MultinomialNB(alpha=alphas[k]))])\n",
    "    mnb_clf = mnb_clf.fit(train_data, trainlabels)\n",
    "    pred = mnb_clf.predict(dev_data)\n",
    "    metrics.accuracy_score(devlabels,pred)\n",
    "    best_nb.append(metrics.accuracy_score(devlabels,pred))\n",
    "bestAlphaAccuracy = max(best_nb)\n",
    "bestAlphaValue = alphas[best_nb.index(bestAlphaAccuracy)]\n",
    "print 'Naive Bayes Baseline:'\n",
    "print 'Best Alpha =', bestAlphaValue, ' accuracy:', bestAlphaAccuracy\n",
    "print ''\n",
    "\n",
    "\n",
    "\n",
    "#Run Logistic Regression classifier\n",
    "log_clf = Pipeline([('vect', CountVectorizer()),('lgclf', LogisticRegression(C=0.5))])\n",
    "log_clf = log_clf.fit(train_data, trainlabels) \n",
    "pred = log_clf.predict(dev_data)        \n",
    "score2= metrics.accuracy_score(devlabels,pred)\n",
    "#print 'Logistic Regression Score:',score2\n",
    "best_logit = []\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 0.5, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "for k in range(len(C)):\n",
    "    log_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('lgclf', LogisticRegression(C=C[k]))]);\n",
    "    log_clf = log_clf.fit(train_data, trainlabels)\n",
    "    pred = log_clf.predict(dev_data)\n",
    "    metrics.accuracy_score(devlabels,pred)\n",
    "    best_logit.append(metrics.accuracy_score(devlabels,pred))\n",
    "    weights = log_clf.named_steps['lgclf'].coef_\n",
    "bestCAccuracy = max(best_logit)\n",
    "bestCValue = C[best_logit.index(bestCAccuracy)]\n",
    "print 'Logistic Regression Baseline:'\n",
    "print 'Best C =', bestCValue, ' accuracy:', bestCAccuracy\n",
    "print ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2020,)\n",
      "505\n",
      "Logistic Regression Baseline:\n",
      "('num who got pizza:', 132)\n",
      "('accuracy:', 0.7168316831683168)\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       Got Pizza       0.77      0.89      0.83       764\n",
      "Didn't get pizza       0.35      0.19      0.24       246\n",
      "\n",
      "     avg / total       0.67      0.72      0.68      1010\n",
      "\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#predictions = predict_probs(rf, test)[:,2]\n",
    "#submission = DataFrame(request_id=real_test[:request_id], requester_received_pizza=predictions)\n",
    "#writetable(\"simple_julia_benchmark.csv\", submission)\n",
    "import re \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def better_preprocessor(s):\n",
    "### STUDENT START ###\n",
    "    repl = re.sub('&', ' and ', s)\n",
    "    repl = repl.lower()\n",
    "    repl = repl.replace('0',' zero ')\n",
    "    repl = repl.replace('1',' one ')\n",
    "    repl = repl.replace('2',' two ')\n",
    "    repl = repl.replace('3',' three ')\n",
    "    repl = repl.replace('4',' four ')\n",
    "    repl = repl.replace('5',' five ')\n",
    "    repl = repl.replace('6',' six ')\n",
    "    repl = repl.replace('7',' seven ')\n",
    "    repl = repl.replace('8',' eight ')\n",
    "    repl = repl.replace('9',' nine ')\n",
    "    repl = re.sub('[^a-z]+',' ', repl)\n",
    "    return repl\n",
    "\n",
    "\n",
    "print train_labels.shape\n",
    "print sum(trainlabels)\n",
    "\n",
    "log_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3),preprocessor=better_preprocessor)),\n",
    "                     ('lgclf', LogisticRegression(penalty='l1', tol=0.1))]);\n",
    "log_clf = log_clf.fit(train_data, trainlabels)\n",
    "pred = log_clf.predict(test_data)\n",
    "acc = metrics.accuracy_score(testlabels,pred)\n",
    "\n",
    "print('Logistic Regression Baseline:')\n",
    "print('num who got pizza:',sum(pred))\n",
    "print('accuracy:', acc)\n",
    "print metrics.classification_report(testlabels, pred,\n",
    "               target_names=categories)\n",
    "print('')\n",
    "\n",
    "predictions = mnb_clf.predict(test_X)\n",
    "print(max(predictions))\n",
    "#print(sum(np.where(predictions==1, 1, 0)))\n",
    "d = {\n",
    "    'request_id' :test_ids, \n",
    "    'requester_received_pizza':predictions\n",
    "}\n",
    "submission = pd.DataFrame(d)\n",
    "#print(submission)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py2k]",
   "language": "python",
   "name": "Python [py2k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
