{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4040, 32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "pd_train = pd.read_json('https://raw.githubusercontent.com/mdemaster/w207_Final_Project/master/train.json', orient='columns')\n",
    "pd_test = pd.read_json('https://raw.githubusercontent.com/mdemaster/w207_Final_Project/master/test.json', orient='columns')\n",
    "\n",
    "np_test = np.array(pd_test)\n",
    "np_train = np.array(pd_train)\n",
    "\n",
    "print np_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (4040,)\n",
      "label shape: (4040,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = np_train[:,7]\n",
    "Y = np_train[:,22]\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print 'data shape: ', X.shape\n",
    "print 'label shape:', Y.shape\n",
    "\n",
    "l=len(X)\n",
    "train_data, train_labels = X[:l/2], Y[:l/2]\n",
    "dev_data, dev_labels = X[l/2:(3*l)/4], Y[l/2:(3*l)/4]\n",
    "test_data, test_labels = X[(3*l)/4:], Y[(3*l)/4:]\n",
    "\n",
    "\n",
    "categories = ['Didn\\'t get pizza','Got Pizza']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sum of train(Got pizza)', 472, \" (Didn't get pizza:)\", 1548)\n",
      "('Sum of dev(Got pizza)', 258, \" (Didn't get pizza:)\", 752)\n",
      "('Sum of test(Got pizza)', 264, \" (Didn't get pizza:)\", 746)\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def better_preprocessor(s):\n",
    "    repl = re.sub('&', ' and ', s)\n",
    "    repl = repl.lower()\n",
    "    repl = repl.replace('0',' zero ')\n",
    "    repl = repl.replace('1',' one ')\n",
    "    repl = repl.replace('2',' two ')\n",
    "    repl = repl.replace('3',' three ')\n",
    "    repl = repl.replace('4',' four ')\n",
    "    repl = repl.replace('5',' five ')\n",
    "    repl = repl.replace('6',' six ')\n",
    "    repl = repl.replace('7',' seven ')\n",
    "    repl = repl.replace('8',' eight ')\n",
    "    repl = repl.replace('9',' nine ')\n",
    "    repl = re.sub('[^a-z]+',' ', repl)\n",
    "    return repl\n",
    "\n",
    "\n",
    "#Use np.where to binarize train and dev set where values above and below 0.5.\n",
    "b=train_labels\n",
    "trainlabels=np.where(b==True, 1, 0)\n",
    "\n",
    "bl=dev_labels\n",
    "devlabels=np.where(bl==True, 1, 0)\n",
    "\n",
    "b2=test_labels\n",
    "testlabels=np.where(b2==True, 1, 0)\n",
    "\n",
    "print('Sum of train(Got pizza)', sum(trainlabels),' (Didn\\'t get pizza:)', len(trainlabels) - sum(trainlabels))\n",
    "print('Sum of dev(Got pizza)', sum(devlabels),' (Didn\\'t get pizza:)', len(devlabels) - sum(devlabels))\n",
    "print('Sum of test(Got pizza)', sum(testlabels),' (Didn\\'t get pizza:)', len(testlabels) - sum(testlabels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Scores...\n",
      "Naive Bayes Baseline:\n",
      "Best Alpha = 1.0  accuracy: 0.750495049505\n",
      "\n",
      "Logistic Regression Baseline:\n",
      "Best C = 0.0001  accuracy: 0.750495049505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run initial vectorizer and fit_transform on train_data and find vocab size from shape attribute.\n",
    "vect=CountVectorizer(ngram_range=(1, 2))\n",
    "data=vect.fit_transform(train_data).toarray()\n",
    "devdata=vect.transform(dev_data).toarray()\n",
    "\n",
    "\n",
    "print 'Baseline Scores...'\n",
    "#Run MultinomialNB Classifier\n",
    "best_nb = []\n",
    "alphas = [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "for k in range(len(alphas)):\n",
    "    mnb_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2),preprocessor=better_preprocessor)), \n",
    "                        ('mnclf', MultinomialNB(alpha=alphas[k]))])\n",
    "    mnb_clf = mnb_clf.fit(train_data, trainlabels)\n",
    "    pred = mnb_clf.predict(dev_data)\n",
    "    metrics.accuracy_score(devlabels,pred)\n",
    "    best_nb.append(metrics.accuracy_score(devlabels,pred))\n",
    "bestAlphaAccuracy = max(best_nb)\n",
    "bestAlphaValue = alphas[best_nb.index(bestAlphaAccuracy)]\n",
    "print 'Naive Bayes Baseline:'\n",
    "print 'Best Alpha =', bestAlphaValue, ' accuracy:', bestAlphaAccuracy\n",
    "print ''\n",
    "\n",
    "\n",
    "\n",
    "#Run Logistic Regression classifier\n",
    "log_clf = Pipeline([('vect', CountVectorizer()),('lgclf', LogisticRegression(C=0.5))])\n",
    "log_clf = log_clf.fit(train_data, trainlabels) \n",
    "pred = log_clf.predict(dev_data)        \n",
    "score2= metrics.accuracy_score(devlabels,pred)\n",
    "#print 'Logistic Regression Score:',score2\n",
    "best_logit = []\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 0.5, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "for k in range(len(C)):\n",
    "    log_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2),preprocessor=better_preprocessor)),\n",
    "                     ('lgclf', LogisticRegression(C=C[k], tol=0.1))]);\n",
    "    log_clf = log_clf.fit(train_data, trainlabels)\n",
    "    pred = log_clf.predict(dev_data)\n",
    "    metrics.accuracy_score(devlabels,pred)\n",
    "    best_logit.append(metrics.accuracy_score(devlabels,pred))\n",
    "    weights = log_clf.named_steps['lgclf'].coef_\n",
    "bestCAccuracy = max(best_logit)\n",
    "bestCValue = C[best_logit.index(bestCAccuracy)]\n",
    "print 'Logistic Regression Baseline:'\n",
    "print 'Best C =', bestCValue, ' accuracy:', bestCAccuracy\n",
    "print ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Baseline:\n",
      "('Pred sum(got pizza):', 37)\n",
      "('Acutal sum(got pizza):', 249)\n",
      "('accuracy:', 0.73069306930693068)\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Didn't get pizza       0.75      0.96      0.84       761\n",
      "       Got Pizza       0.19      0.03      0.05       249\n",
      "\n",
      "     avg / total       0.61      0.73      0.65      1010\n",
      "\n",
      "\n",
      "(2020,)\n",
      "positive weights:\n",
      "Feature Name: my first check\n",
      "7.26684098015\n",
      "\n",
      "Feature Name: because of the\n",
      "7.00823699016\n",
      "\n",
      "Feature Name: to ask for\n",
      "6.51943502784\n",
      "\n",
      "Feature Name: an empty stomach\n",
      "6.24212919068\n",
      "\n",
      "Feature Name: some kind redditor\n",
      "5.87033434187\n",
      "\n",
      "[u'my first check', u'because of the', u'to ask for', u'an empty stomach', u'some kind redditor']\n",
      "\n",
      "negative weights:\n",
      "Feature Name: some pizza to\n",
      "-4.99748697751\n",
      "\n",
      "Feature Name: would be awesome\n",
      "-4.99389088301\n",
      "\n",
      "Feature Name: to get pizza\n",
      "-4.80528637052\n",
      "\n",
      "Feature Name: me and the\n",
      "-4.54810714418\n",
      "\n",
      "Feature Name: started new job\n",
      "-4.38352364647\n",
      "\n",
      "[u'some pizza to', u'would be awesome', u'to get pizza', u'me and the', u'started new job']\n",
      "\n",
      "predicted prob: [[-0.26474765 -1.45843323]\n",
      " [-0.15471359 -1.9425393 ]\n",
      " [-0.67182048 -0.71493864]\n",
      " ..., \n",
      " [-0.62755125 -0.76334989]\n",
      " [-4.24617018 -0.01442247]\n",
      " [-0.06239698 -2.80527473]]\n",
      "Logistic Regression Baseline:\n",
      "('Pred sum(got pizza):', 142)\n",
      "('Acutal sum(got pizza):', 249)\n",
      "('accuracy:', 0.70198019801980194)\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Didn't get pizza       0.76      0.87      0.82       761\n",
      "       Got Pizza       0.32      0.18      0.23       249\n",
      "\n",
      "     avg / total       0.65      0.70      0.67      1010\n",
      "\n",
      "\n",
      "Actual Test data:\n",
      "('Test data shape: ', (1631,))\n",
      "('Pred sum(got pizza):', 247)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mnb_clf = Pipeline([('vect', CountVectorizer(preprocessor=better_preprocessor)), \n",
    "                        ('mnclf', MultinomialNB())])\n",
    "mnb_clf = mnb_clf.fit(train_data, trainlabels)\n",
    "pred = mnb_clf.predict(test_data)\n",
    "acc = metrics.accuracy_score(testlabels,pred)\n",
    "print('Naive Bayes Baseline:')\n",
    "print('Pred sum(got pizza):',sum(pred))\n",
    "print('Acutal sum(got pizza):',sum(testlabels))\n",
    "print('accuracy:', acc)\n",
    "print metrics.classification_report(testlabels, pred,\n",
    "               target_names=categories)\n",
    "print('')\n",
    "\n",
    "log_clf = Pipeline([('vect', TfidfVectorizer(preprocessor=better_preprocessor,\n",
    "                                             ngram_range=(3,5),max_df=0.5, min_df=3)),\n",
    "                     ('lgclf', LogisticRegression(C=100, tol=0.1))]);\n",
    "print train_data.shape\n",
    "log_clf = log_clf.fit(train_data, trainlabels)\n",
    "pred = log_clf.predict(test_data)\n",
    "predProb = log_clf.predict_log_proba(test_data)\n",
    "acc = metrics.accuracy_score(testlabels,pred)\n",
    "\n",
    "\n",
    "vect = log_clf.named_steps['vect']\n",
    "lgclf = log_clf.named_steps['lgclf']\n",
    "features = tfidvec.get_feature_names();\n",
    "weights = lgclf.coef_\n",
    "\n",
    "print 'positive weights:'\n",
    "weight_indexes = []\n",
    "positive_features = []\n",
    "weight_index = weights[0].argsort()[-5:][::-1].tolist()\n",
    "weight_indexes += (weight_index)    \n",
    "for i in range(len(weight_indexes)):\n",
    "        index = weight_indexes[i]\n",
    "        positive_features.append(features[index])\n",
    "        print 'Feature Name:', features[index]\n",
    "        print weights[0][index]\n",
    "        print ''\n",
    "print positive_features\n",
    "print ''\n",
    "print 'negative weights:'\n",
    "weight_indexes = []\n",
    "negative_features = []\n",
    "weight_index = weights[0].argsort()[:5].tolist()\n",
    "weight_indexes += (weight_index)    \n",
    "for i in range(len(weight_indexes)):\n",
    "        index = weight_indexes[i]\n",
    "        negative_features.append(features[index])\n",
    "        print 'Feature Name:', features[index]\n",
    "        print weights[0][index]\n",
    "        print ''\n",
    "print negative_features\n",
    "print ''\n",
    "\n",
    "\n",
    "print 'predicted prob:', predProb\n",
    "\n",
    "print('Logistic Regression Baseline:')\n",
    "print('Pred sum(got pizza):',sum(pred))\n",
    "print('Acutal sum(got pizza):',sum(testlabels))\n",
    "print('accuracy:', acc)\n",
    "print metrics.classification_report(testlabels, pred,\n",
    "               target_names=categories)\n",
    "print('')\n",
    "\n",
    "\n",
    "test_ids = np_test[:,1]\n",
    "test_X = np_test[:,2]\n",
    "predictions = log_clf.predict(test_X)\n",
    "\n",
    "\n",
    "print('Actual Test data:')\n",
    "print('Test data shape: ', test_X.shape)\n",
    "print('Pred sum(got pizza):',sum(predictions))\n",
    "#print(sum(np.where(predictions==1, 1, 0)))\n",
    "d = {\n",
    "    'request_id' :test_ids, \n",
    "    'requester_received_pizza':predictions\n",
    "}\n",
    "submission = pd.DataFrame(d)\n",
    "#print(submission)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py2k]",
   "language": "python",
   "name": "Python [py2k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
