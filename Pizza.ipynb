{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4040, 32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "pd_train = pd.read_json('https://raw.githubusercontent.com/mdemaster/w207_Final_Project/master/train.json', orient='columns')\n",
    "pd_test = pd.read_json('https://raw.githubusercontent.com/mdemaster/w207_Final_Project/master/test.json', orient='columns')\n",
    "\n",
    "np_test = np.array(pd_test)\n",
    "np_train = np.array(pd_train)\n",
    "\n",
    "print np_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (4040,)\n",
      "label shape: (4040,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = np_train[:,6]\n",
    "Y = np_train[:,22]\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print 'data shape: ', X.shape\n",
    "print 'label shape:', Y.shape\n",
    "\n",
    "l=len(X)\n",
    "train_data, train_labels = X[:l/2], Y[:l/2]\n",
    "dev_data, dev_labels = X[l/2:(3*l)/4], Y[l/2:(3*l)/4]\n",
    "test_data, test_labels = X[(3*l)/4:], Y[(3*l)/4:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Scores...\n",
      "Naive Bayes Baseline:\n",
      "Best Alpha = 10.0  accuracy: 0.755445544554\n",
      "\n",
      "Logistic Regression Baseline:\n",
      "Best C = 0.0001  accuracy: 0.756435643564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run initial vectorizer and fit_transform on train_data and find vocab size from shape attribute.\n",
    "vect=CountVectorizer()\n",
    "data=vect.fit_transform(train_data).toarray()\n",
    "devdata=vect.transform(dev_data).toarray()\n",
    "\n",
    "\n",
    "#Use np.where to binarize train and dev set where values above and below 0.5.\n",
    "b=train_labels\n",
    "trainlabels=np.where(b==True, 1, 0)\n",
    "\n",
    "bl=dev_labels\n",
    "devlabels=np.where(bl==True, 1, 0)\n",
    "\n",
    "b2=test_labels\n",
    "testlabels=np.where(b2==True, 1, 0)\n",
    "\n",
    "categories = ['Got Pizza', 'Didn\\'t get pizza']\n",
    "\n",
    "print 'Baseline Scores...'\n",
    "#Run MultinomialNB Classifier\n",
    "# mnb_clf = Pipeline([('vect', CountVectorizer()), ('mnclf',MultinomialNB(alpha=0.01))])\n",
    "# mnb_clf = mnb_clf.fit(train_data, trainlabels)\n",
    "# pred = mnb_clf.predict(dev_data)\n",
    "# score1=metrics.accuracy_score(devlabels,pred)\n",
    "# print 'Naive Bayes Score:',score1\n",
    "best_nb = []\n",
    "alphas = [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "for k in range(len(alphas)):\n",
    "    mnb_clf = Pipeline([('vect', CountVectorizer()), ('mnclf', MultinomialNB(alpha=alphas[k]))])\n",
    "    mnb_clf = mnb_clf.fit(train_data, trainlabels)\n",
    "    pred = mnb_clf.predict(dev_data)\n",
    "    metrics.accuracy_score(devlabels,pred)\n",
    "    best_nb.append(metrics.accuracy_score(devlabels,pred))\n",
    "bestAlphaAccuracy = max(best_nb)\n",
    "bestAlphaValue = alphas[best_nb.index(bestAlphaAccuracy)]\n",
    "print 'Naive Bayes Baseline:'\n",
    "print 'Best Alpha =', bestAlphaValue, ' accuracy:', bestAlphaAccuracy\n",
    "print ''\n",
    "\n",
    "\n",
    "\n",
    "#Run Logistic Regression classifier\n",
    "log_clf = Pipeline([('vect', CountVectorizer()),('lgclf', LogisticRegression(C=0.5))])\n",
    "log_clf = log_clf.fit(train_data, trainlabels) \n",
    "pred = log_clf.predict(dev_data)        \n",
    "score2= metrics.accuracy_score(devlabels,pred)\n",
    "#print 'Logistic Regression Score:',score2\n",
    "best_logit = []\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 0.5, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "for k in range(len(C)):\n",
    "    log_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('lgclf', LogisticRegression(C=C[k]))]);\n",
    "    log_clf = log_clf.fit(train_data, trainlabels)\n",
    "    pred = log_clf.predict(dev_data)\n",
    "    metrics.accuracy_score(devlabels,pred)\n",
    "    best_logit.append(metrics.accuracy_score(devlabels,pred))\n",
    "    weights = log_clf.named_steps['lgclf'].coef_\n",
    "bestCAccuracy = max(best_logit)\n",
    "bestCValue = C[best_logit.index(bestCAccuracy)]\n",
    "print 'Logistic Regression Baseline:'\n",
    "print 'Best C =', bestCValue, ' accuracy:', bestCAccuracy\n",
    "print ''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py2k]",
   "language": "python",
   "name": "Python [py2k]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
