{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w207 Final Project\n",
    "#### *Random Acts of Pizza Kaggle Competition Project* - by Marcus DeMaster and Chuqing He\n",
    "\n",
    "Using a dataset of 4040 Reddit requests for pizza, we attempt to build a machine learning model that predicts if a request for pizza results in successfully receiving a pizza.\n",
    "\n",
    "We investigate several types of models that we import below from the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import *\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use pandas to read the training set and test set in json file format from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Download training and test datasets.\n",
    "pd_train = pd.read_json('https://raw.githubusercontent.com/mdemaster/w207_Final_Project/master/train.json', orient='columns')\n",
    "pd_test = pd.read_json('https://raw.githubusercontent.com/mdemaster/w207_Final_Project/master/test.json', orient='columns')\n",
    "\n",
    "#Move label field 'requester_received_pizza' to first field.\n",
    "pizza = pd_train['requester_received_pizza']\n",
    "pd_train.drop(labels=['requester_received_pizza'], axis=1,inplace = True)\n",
    "pd_train.insert(0, 'requester_received_pizza', pizza)\n",
    "\n",
    "#Create numpy arrays datasets\n",
    "np_test = np.array(pd_test)\n",
    "np_train = np.array(pd_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discovered that the test set only has 17 fields compared to the 32 present in the training set.  The test set also doesn't have a field titled, \"requestor_received_pizza\", which is the field we are using for the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training set fields: 32                               Number of test set fields:  17                                                     \n",
      "===============================================================================================================\n",
      "requester_received_pizza                                        giver_username_if_known\n",
      "giver_username_if_known                                         request_id\n",
      "number_of_downvotes_of_request_at_retrieval                     request_text_edit_aware\n",
      "number_of_upvotes_of_request_at_retrieval                       request_title\n",
      "post_was_edited                                                 requester_account_age_in_days_at_request\n",
      "request_id                                                      requester_days_since_first_post_on_raop_at_request\n",
      "request_number_of_comments_at_retrieval                         requester_number_of_comments_at_request\n",
      "request_text                                                    requester_number_of_comments_in_raop_at_request\n",
      "request_text_edit_aware                                         requester_number_of_posts_at_request\n",
      "request_title                                                   requester_number_of_posts_on_raop_at_request\n",
      "requester_account_age_in_days_at_request                        requester_number_of_subreddits_at_request\n",
      "requester_account_age_in_days_at_retrieval                      requester_subreddits_at_request\n",
      "requester_days_since_first_post_on_raop_at_request              requester_upvotes_minus_downvotes_at_request\n",
      "requester_days_since_first_post_on_raop_at_retrieval            requester_upvotes_plus_downvotes_at_request\n",
      "requester_number_of_comments_at_request                         requester_username\n",
      "requester_number_of_comments_at_retrieval                       unix_timestamp_of_request\n",
      "requester_number_of_comments_in_raop_at_request                 unix_timestamp_of_request_utc\n",
      "requester_number_of_comments_in_raop_at_retrieval               \n",
      "requester_number_of_posts_at_request                            \n",
      "requester_number_of_posts_at_retrieval                          \n",
      "requester_number_of_posts_on_raop_at_request                    \n",
      "requester_number_of_posts_on_raop_at_retrieval                  \n",
      "requester_number_of_subreddits_at_request                       \n",
      "requester_subreddits_at_request                                 \n",
      "requester_upvotes_minus_downvotes_at_request                    \n",
      "requester_upvotes_minus_downvotes_at_retrieval                  \n",
      "requester_upvotes_plus_downvotes_at_request                     \n",
      "requester_upvotes_plus_downvotes_at_retrieval                   \n",
      "requester_user_flair                                            \n",
      "requester_username                                              \n",
      "unix_timestamp_of_request                                       \n",
      "unix_timestamp_of_request_utc                                   \n"
     ]
    }
   ],
   "source": [
    "#Print illustration of field differences in training and test sets.\n",
    "train_cols=str(len(pd_train.columns.values))\n",
    "test_cols=str(len(pd_test.columns.values))\n",
    "\n",
    "print 'Number of training set fields:',train_cols.ljust(31,' '),' Number of test set fields: ',test_cols.ljust(55,' ')\n",
    "print '==============================================================================================================='\n",
    "for i in range(len(pd_train.columns.values)):\n",
    "    train=pd_train.columns.values[i]\n",
    "    if i<len(pd_test.columns.values):\n",
    "        test=pd_test.columns.values[i]\n",
    "    else:\n",
    "        test=''\n",
    "    print train.ljust(55,' '), '       ', test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of these discrepancies in the given test data, we decided to split the train_data into a smaller training set, a dev set, and a test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (4040, 31)\n",
      "label shape: (4040,)\n",
      "train data shape: (2020, 31)\n",
      "train label shape: (2020,)\n",
      "dev data shape: (1010, 31)\n",
      "dev label shape: (1010,)\n",
      "test data shape: (1010, 31)\n",
      "test label shape: (1010,)\n"
     ]
    }
   ],
   "source": [
    "#Split dataset into predictor data,X, and labels,Y.\n",
    "X = np_train[:,1:]\n",
    "Y = np_train[:,0]\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "#Print data and label array shapes to confirm they are the same.\n",
    "print 'data shape: ', X.shape\n",
    "print 'label shape:', Y.shape\n",
    "\n",
    "#Assign first half of data to training set, 3rd quarter of data to dev set, and 4th quarter of data to test set.\n",
    "l=len(X)\n",
    "train_data, train_labels = X[:l/2], np.where(Y[:l/2][:]==True,1,0)\n",
    "dev_data, dev_labels = X[l/2:(3*l)/4], np.where(Y[l/2:(3*l)/4][:]==True,1,0)\n",
    "test_data, test_labels = X[(3*l)/4:], np.where(Y[(3*l)/4:][:]==True,1,0)\n",
    "\n",
    "print 'train data shape:', train_data.shape\n",
    "print 'train label shape:', train_labels.shape\n",
    "print 'dev data shape:', dev_data.shape\n",
    "print 'dev label shape:', dev_labels.shape\n",
    "print 'test data shape:', test_data.shape\n",
    "print 'test label shape:', test_labels.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Attempt(Baseline approach): Using CountVectorizer with Multinomial Naive Bayes and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Baseline:\n",
      "('Pred sum(got pizza):', 18)\n",
      "('Acutal sum(got pizza):', 260)\n",
      "('accuracy:', 0.73465346534653464)\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Didn't get pizza       0.74      0.98      0.85       750\n",
      "       Got Pizza       0.28      0.02      0.04       260\n",
      "\n",
      "     avg / total       0.62      0.73      0.64      1010\n",
      "\n",
      "\n",
      "Logistic Regression Baseline:\n",
      "('Pred sum(got pizza):', 197)\n",
      "('Acutal sum(got pizza):', 260)\n",
      "('accuracy:', 0.68217821782178223)\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Didn't get pizza       0.76      0.83      0.79       750\n",
      "       Got Pizza       0.35      0.26      0.30       260\n",
      "\n",
      "     avg / total       0.66      0.68      0.67      1010\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categories = ['Didn\\'t get pizza','Got Pizza']\n",
    "mnb_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                        ('mnclf', MultinomialNB())])\n",
    "mnb_clf = mnb_clf.fit(train_data[:,7], train_labels)\n",
    "pred = mnb_clf.predict(test_data[:,7])\n",
    "acc = metrics.accuracy_score(test_labels,pred)\n",
    "print('Naive Bayes Baseline:')\n",
    "print('Pred sum(got pizza):',sum(pred))\n",
    "print('Acutal sum(got pizza):',sum(test_labels))\n",
    "print('accuracy:', acc)\n",
    "print metrics.classification_report(test_labels, pred,\n",
    "               target_names=categories)\n",
    "print('')\n",
    "\n",
    "log_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('lgclf', LogisticRegression(C=100, tol=0.1))]);\n",
    "log_clf = log_clf.fit(train_data[:,7], train_labels)\n",
    "pred = log_clf.predict(test_data[:,7])\n",
    "acc = metrics.accuracy_score(test_labels,pred)\n",
    "\n",
    "print('Logistic Regression Baseline:')\n",
    "print('Pred sum(got pizza):',sum(pred))\n",
    "print('Acutal sum(got pizza):',sum(test_labels))\n",
    "print('accuracy:', acc)\n",
    "print metrics.classification_report(test_labels, pred,\n",
    "               target_names=categories)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the CountVectorizer to transform the data and get a vocabulary dictionary, then we used Naive Bayes and Logistic Regression Classifier to predict the test data. Overall our accuracy was around 70%; however, the f1-score is very low, and we knew we had to try other methods to improve our results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to Term Frequency Vectorizer and fit a logistic regression model to that. We also used a preprocessor to sanitize the data set. This way we can figure out the top weighted positive and negative features(words). These weights will later be used to binarize the text in GMM. To binarize the user input text, we check to see whether the user input contains any of the features from the feature array, if the user input contains one of the feature, we add it to the weightsum. If the weight sum is greater than 0, then we tag the user input with 1, otherwise we tag it with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive weights:\n",
      "[(u'thanks', 4.681132086421667), (u'my paycheck', 4.4402567754003037), (u'major', 4.2705901237262918), (u'well', 4.2373923370888393), (u'last two', 4.1505433256400268)]\n",
      "\n",
      "negative weights:\n",
      "[(u'or', -4.7296506481157401), (u'free', -4.4018368412321358), (u'say', -3.9620912701616957), (u'to say', -3.9309081988072769), (u'friend', -3.9305629444589187)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def better_preprocessor(s):\n",
    "    repl = re.sub('&', ' and ', s)\n",
    "    repl = repl.lower()\n",
    "    repl = repl.replace('0',' zero ')\n",
    "    repl = repl.replace('1',' one ')\n",
    "    repl = repl.replace('2',' two ')\n",
    "    repl = repl.replace('3',' three ')\n",
    "    repl = repl.replace('4',' four ')\n",
    "    repl = repl.replace('5',' five ')\n",
    "    repl = repl.replace('6',' six ')\n",
    "    repl = repl.replace('7',' seven ')\n",
    "    repl = repl.replace('8',' eight ')\n",
    "    repl = repl.replace('9',' nine ')\n",
    "    repl = re.sub('[^a-z]+',' ', repl)\n",
    "    return repl\n",
    "\n",
    " # tfid and log clg, get top positive weights and top negative weights\n",
    "tfidvec = TfidfVectorizer(preprocessor=better_preprocessor, ngram_range=(1,3),max_df=0.5, min_df=3);\n",
    "train_X = tfidvec.fit_transform(train_data[:,7])\n",
    "log_clf = LogisticRegression(C=100, tol=0.1)\n",
    "log_clf = log_clf.fit(train_X, train_labels)\n",
    "features = tfidvec.get_feature_names();\n",
    "weights = log_clf.coef_\n",
    "\n",
    "print 'positive weights:'\n",
    "weight_indexes = []\n",
    "positive_features = []\n",
    "weight_index = weights[0].argsort()[-5:][::-1].tolist()\n",
    "weight_indexes += (weight_index)    \n",
    "for i in range(len(weight_indexes)):\n",
    "    index = weight_indexes[i]\n",
    "    positive_features.append((features[index], weights[0][index]))\n",
    "#             print 'Feature Name:', features[index]\n",
    "#             print weights[0][index]\n",
    "#             print ''\n",
    "print positive_features\n",
    "print ''\n",
    "print 'negative weights:'\n",
    "weight_indexes = []\n",
    "negative_features = []\n",
    "weight_index = weights[0].argsort()[:5].tolist()\n",
    "weight_indexes += (weight_index)    \n",
    "for i in range(len(weight_indexes)):\n",
    "    index = weight_indexes[i]\n",
    "    negative_features.append((features[index], weights[0][index]))\n",
    "#             print 'Feature Name:', features[index]\n",
    "#             print weights[0][index]\n",
    "#             print ''\n",
    "print negative_features\n",
    "weight_features = positive_features + negative_features\n",
    "# print 'total features:'\n",
    "# print weight_features\n",
    "print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the dataset fields, we see that there are a number of scalar fields with highly variable distributions.  In order to normalize this information and utilize it for a Gaussian Mixture Model, we create new train, dev, and test sets with binarized fields with a uniform distribution binning criteria.\n",
    "\n",
    "For the first Binarize function, we started off with three bins per scalar field and even splits in the data ranges for the bin boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dictionary of scalar field numbers and their corresponding number of bins.\n",
    "fields_bins = {\n",
    "1:3, 2:3, 5:3, 9:3, 10:3, 11:3, 12:3, 13:3, 14:3, 15:3, 16:3, 17:3, 18:3, 19:3, 20:3, 21:3, 23:3, 24:3, 25:3, 26:3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Binarize1(fields_bins,X):\n",
    "    #Binarize Training Data\n",
    "    train_data=X[:l/2]\n",
    "    s=train_data.shape[0]\n",
    "    bin_train=np.where(train_data[:,0]==u'N/A',0.,1.).reshape(s,1)\n",
    "\n",
    "    for f, b in fields_bins.items():\n",
    "        col=train_data[:,f]\n",
    "        sort=np.sort(col)\n",
    "        bin_train = np.column_stack((bin_train,np.where(col<sort[s/b],1.,0.).reshape(s,1)))\n",
    "        hist_bins=[0]\n",
    "        for i in range(b-2):\n",
    "            x=sort[(i+1)*s/b]\n",
    "            y=sort[(i+2)*s/b]\n",
    "            bin_train = np.column_stack((bin_train,np.where((col>=x) & (col<y),1.,0.).reshape(s,1)))\n",
    "            hist_bins=np.append(hist_bins,x)\n",
    "        hist_bins=np.append(hist_bins,sort[-1])\n",
    "        bin_train = np.column_stack((bin_train,np.where(col>=sort[(b-1)*s/b],1.,0.).reshape(s,1)))\n",
    "       \n",
    "    #Binarize Dev Data\n",
    "    dev_data = X[l/2:(3*l)/4]\n",
    "    s1=dev_data.shape[0]\n",
    "    bin_dev=np.where(dev_data[:,0]==u'N/A',0.,1.).reshape(s1,1)\n",
    "\n",
    "    for f, b in fields_bins.items(): \n",
    "        col=dev_data[:,f]\n",
    "        sort=np.sort(col)\n",
    "        bin_dev = np.column_stack((bin_dev,np.where(col<sort[s1/b],1.,0.).reshape(s1,1)))\n",
    "        for i in range(b-2):\n",
    "            x=sort[(i+1)*s1/b]\n",
    "            y=sort[(i+2)*s1/b]\n",
    "            bin_dev = np.column_stack((bin_dev,np.where((col>=x) & (col<y),1.,0.).reshape(s1,1)))\n",
    "        bin_dev = np.column_stack((bin_dev,np.where(col>=sort[(b-1)*s1/b],1.,0.).reshape(s1,1)))  \n",
    "        \n",
    "    #Binarize Test Data\n",
    "    test_data = X[(3*l)/4:]\n",
    "    s2=test_data.shape[0]\n",
    "    bin_test=np.where(test_data[:,0]==u'N/A',0.,1.).reshape(s2,1)\n",
    "\n",
    "    for f, b in fields_bins.items():\n",
    "        col=test_data[:,f]\n",
    "        sort=np.sort(col)\n",
    "        bin_test = np.column_stack((bin_test,np.where(col<sort[s2/b],1.,0.).reshape(s2,1)))\n",
    "        for i in range(b-2):\n",
    "            x=sort[(i+1)*s2/b]\n",
    "            y=sort[(i+2)*s2/b]\n",
    "            bin_test = np.column_stack((bin_test,np.where((col>=x) & (col<y),1.,0.).reshape(s2,1)))\n",
    "        bin_test = np.column_stack((bin_test,np.where(col>=sort[(b-1)*s2/b],1.,0.).reshape(s2,1)))\n",
    "    \n",
    "    return [bin_train,bin_dev,bin_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we built a function to take the binned training data and binned dev data and run a Gaussian mixture model on this data.  The function loops through the four covariance types, a range of PCA components, and a range of GMM components to find the model with the most accurate fit. The top 5 models run on the binned dev data and the top 5 models run on the binned test data are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mixture_model(bin_train,bin_dev,bin_test):\n",
    "    \n",
    "    dev_test=[[bin_dev,dev_labels],[bin_test,test_labels]]\n",
    "    for i,j in enumerate(dev_test):\n",
    "        experiments=[]\n",
    "        for c_type in ['spherical', 'diag', 'tied', 'full']:\n",
    "            for p_comp in range(1,60):\n",
    "                for g_comp in range(1,9):\n",
    "\n",
    "                    params=((3+p_comp)*g_comp)*2\n",
    "                    if params<=100:\n",
    "                        #Run PCA with two components\n",
    "                        pca = PCA(p_comp)\n",
    "\n",
    "                        #Assign train data and labels to x and y for fitting and transforming.\n",
    "                        x=bin_train\n",
    "                        y=train_labels\n",
    "\n",
    "                        #Transform train data and fit it with labels to 2-component projected PCA model.\n",
    "                        proj_train=pca.fit(x,y).transform(x)\n",
    "\n",
    "                        #Transform test data to 2-component projected PCA model\n",
    "                        proj_test=pca.transform(j[0])\n",
    "\n",
    "                        #Filter Projected data by positive examples.\n",
    "                        pos=proj_train[y == 1]\n",
    "                        neg=proj_train[y == 0]\n",
    "\n",
    "                        #Fit GMM model to positive and negative train datasets.\n",
    "                        gmm_pos = GMM(n_components=g_comp, covariance_type=c_type).fit(pos)\n",
    "                        gmm_neg = GMM(n_components=g_comp, covariance_type=c_type).fit(neg)\n",
    "\n",
    "                        #Get positive and negative GMM model scores for test data.\n",
    "                        gmm_pos_score=np.array(gmm_pos.score(proj_test))\n",
    "                        gmm_neg_score=np.array(gmm_neg.score(proj_test))\n",
    "\n",
    "                        #Merge score arrays and check which score is greater to determine positive/negative classes.\n",
    "                        point_scores=np.column_stack((gmm_pos_score,gmm_neg_score))\n",
    "                        gmm_pred=np.where(point_scores[:,0]>point_scores[:,1], 1, 0)\n",
    "\n",
    "                        #Calculate accuracy of merged scoring model method by comparing predicted classes with test_labels.  \n",
    "                        accuracy = 1-np.mean(gmm_pred != j[1])\n",
    "\n",
    "                        #Append model parameters and scores to experiments list\n",
    "                        experiments.append([p_comp,g_comp,c_type,accuracy,params])\n",
    "\n",
    "        #Make experiments an array and sort by descending accuracy\n",
    "        experiments = np.array(experiments)\n",
    "        experiments = experiments[np.argsort(experiments[:, 3])[::-1]]\n",
    "        if i == 0:set_='Dev Set'\n",
    "        else:set_='Test Set'\n",
    "        #Print results of experiments\n",
    "        print 'Top Scoring GMM Models for ',set_\n",
    "        print 'PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters'\n",
    "\n",
    "        for i in  experiments[:5]:\n",
    "            print '%14s  ||' %(i[0])+'%16s  ||' %(i[1])+'%17s  ||' %(i[2])+'  %.4f    ||' %(float(i[3]))+'%10s ' %(i[4])\n",
    "        print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see that the GMM models on the binned datasets shows improved accuracy at around 82% on the test set and a little lower on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Scoring GMM Models for  Dev Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            27  ||               1  ||             tied  ||  0.8267    ||        60 \n",
      "            27  ||               1  ||             full  ||  0.8267    ||        60 \n",
      "            28  ||               1  ||             tied  ||  0.8228    ||        62 \n",
      "            28  ||               1  ||             full  ||  0.8228    ||        62 \n",
      "            29  ||               1  ||             tied  ||  0.8208    ||        64 \n",
      "\n",
      "Top Scoring GMM Models for  Test Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            29  ||               1  ||             tied  ||  0.7960    ||        64 \n",
      "            29  ||               1  ||             full  ||  0.7960    ||        64 \n",
      "            28  ||               1  ||             full  ||  0.7941    ||        62 \n",
      "            28  ||               1  ||             tied  ||  0.7941    ||        62 \n",
      "            27  ||               1  ||             full  ||  0.7931    ||        60 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run mixture model on first binarized train set\n",
    "d = Binarize1(fields_bins,X)\n",
    "bin_train,bin_dev,bin_test = d[0],d[1],d[2]\n",
    "mixture_model(bin_train,bin_dev,bin_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a second binarize function using the numpy histogram function, which creates normalized binning boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Binarize2(fields_bins,X):\n",
    "    binnum=3\n",
    "    \n",
    "    #Binarize Training Data\n",
    "    train_data=X[:l/2]\n",
    "    s=train_data.shape[0]\n",
    "    bin_train=np.where(train_data[:,0]==u'N/A',0.,1.).reshape(s,1)\n",
    "       \n",
    "    for f, b in fields_bins.items():\n",
    "        col=train_data[:,f]\n",
    "        h=np.histogram(col,bins=binnum,normed=True)[1]\n",
    "        bin_train = np.column_stack((bin_train,np.where(col<h[1],1.,0.).reshape(s,1)))\n",
    "        for i in range(len(h)-2):\n",
    "            bin_train = np.column_stack((bin_train,np.where((col>=h[i+1]) & (col<h[i+2]),1.,0.).reshape(s,1)))\n",
    "        bin_train = np.column_stack((bin_train,np.where(col>=h[-2],1.,0.).reshape(s,1)))\n",
    "    \n",
    "\n",
    "    #Binarize Dev Data\n",
    "    dev_data = X[l/2:(3*l)/4]\n",
    "    s1=dev_data.shape[0]\n",
    "    bin_dev=np.where(dev_data[:,0]==u'N/A',0.,1.).reshape(s1,1)\n",
    "\n",
    "    for f, b in fields_bins.items():\n",
    "        col=dev_data[:,f]\n",
    "        h=np.histogram(col,bins=binnum,normed=True)[1]\n",
    "        bin_dev = np.column_stack((bin_dev,np.where(col<h[1],1.,0.).reshape(s1,1)))\n",
    "        for i in range(len(h)-2):\n",
    "            bin_dev = np.column_stack((bin_dev,np.where((col>=h[i+1]) & (col<h[i+2]),1.,0.).reshape(s1,1)))\n",
    "        bin_dev = np.column_stack((bin_dev,np.where(col>=h[-2],1.,0.).reshape(s1,1)))\n",
    "        \n",
    "    #Binarize Test Data\n",
    "    test_data = X[(3*l)/4:]\n",
    "    s2=test_data.shape[0]\n",
    "    bin_test=np.where(test_data[:,0]==u'N/A',0.,1.).reshape(s2,1)\n",
    "    \n",
    "    for f, b in fields_bins.items():\n",
    "        col=test_data[:,f]\n",
    "        h=np.histogram(col,bins=binnum,normed=True)[1]\n",
    "        bin_test = np.column_stack((bin_test,np.where(col<h[1],1.,0.).reshape(s2,1)))\n",
    "        for i in range(len(h)-2):\n",
    "            bin_test = np.column_stack((bin_test,np.where((col>=h[i+1]) & (col<h[i+2]),1.,0.).reshape(s2,1)))\n",
    "        bin_test = np.column_stack((bin_test,np.where(col>=h[-2],1.,0.).reshape(s2,1)))\n",
    "        \n",
    "    return [bin_train,bin_dev,bin_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running Binarize2() and the mixture_model functions, we see an improvement in accuracy on both the dev set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Scoring GMM Models for  Dev Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            12  ||               3  ||             tied  ||  0.8366    ||        90 \n",
      "             7  ||               3  ||             tied  ||  0.8356    ||        60 \n",
      "             8  ||               3  ||             tied  ||  0.8356    ||        66 \n",
      "            12  ||               1  ||             tied  ||  0.8356    ||        30 \n",
      "            12  ||               1  ||             full  ||  0.8356    ||        30 \n",
      "\n",
      "Top Scoring GMM Models for  Test Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            13  ||               3  ||             tied  ||  0.8198    ||        96 \n",
      "            12  ||               3  ||             tied  ||  0.8188    ||        90 \n",
      "            16  ||               1  ||             full  ||  0.8188    ||        38 \n",
      "            16  ||               2  ||             tied  ||  0.8188    ||        76 \n",
      "            16  ||               1  ||             tied  ||  0.8188    ||        38 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run mixture model on second binned train set\n",
    "d = Binarize2(fields_bins,X)\n",
    "bin_train,bin_dev,bin_test = d[0],d[1],d[2]\n",
    "mixture_model(bin_train,bin_dev,bin_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To binarize the user input text, we check to see whether the user input contains any of the features from the feature array, if the user input contains one of the feature, we add it to the weightsum.  If the weight sum is greater than 0, then we assign 1 to the column, otherwise we assign 0.  This is done below in Binarize3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Binarize3(bin_train,bin_dev,bin_test):\n",
    "    \n",
    "    #Add text weight field to binarized train data\n",
    "    text_weights_f_arr = []\n",
    "    for line in train_data[:,7]:\n",
    "        weightsum = 0\n",
    "        for feat in weight_features: \n",
    "            if feat[0] in line.lower(): \n",
    "                weightsum += feat[1]\n",
    "        if weightsum > 0: \n",
    "            text_weights_f_arr.append(1)\n",
    "        else:\n",
    "            text_weights_f_arr.append(0)\n",
    "    bin_train = np.column_stack((bin_train, np.asarray(text_weights_f_arr)))\n",
    "\n",
    "    #Add text weight field to binarized dev data\n",
    "    text_weights_f_arr = []\n",
    "    for line in dev_data[:,7]:\n",
    "        weightsum = 0\n",
    "        for feat in weight_features: \n",
    "            if feat[0] in line.lower(): \n",
    "                weightsum += feat[1]\n",
    "        if weightsum > 0: \n",
    "            text_weights_f_arr.append(1)\n",
    "        else:\n",
    "            text_weights_f_arr.append(0)\n",
    "    bin_dev = np.column_stack((bin_dev, np.asarray(text_weights_f_arr)))\n",
    "        \n",
    "    #Add text weight field to binarized test data\n",
    "\n",
    "    text_weights_f_arr = []\n",
    "    for line in test_data[:,7]:\n",
    "        weightsum = 0\n",
    "        for feat in weight_features: \n",
    "            if feat[0] in line.lower(): \n",
    "                weightsum += feat[1]\n",
    "        if weightsum > 0: \n",
    "            text_weights_f_arr.append(1)\n",
    "        else:\n",
    "            text_weights_f_arr.append(0)\n",
    "    bin_test = np.column_stack((bin_test, np.asarray(text_weights_f_arr)))\n",
    "        \n",
    "    return [bin_train,bin_dev,bin_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the data output from Binarize2, we run Binarize3 to add the text feature weights as a binarized field.  Unfortunately this doesn't improve the scores at all.  If anything, they decrease a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Scoring GMM Models for  Dev Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            11  ||               3  ||             tied  ||  0.8356    ||        84 \n",
      "             8  ||               3  ||             tied  ||  0.8356    ||        66 \n",
      "             7  ||               3  ||             tied  ||  0.8356    ||        60 \n",
      "            10  ||               3  ||             tied  ||  0.8347    ||        78 \n",
      "            13  ||               3  ||             tied  ||  0.8347    ||        96 \n",
      "\n",
      "Top Scoring GMM Models for  Test Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            11  ||               3  ||             tied  ||  0.8188    ||        84 \n",
      "            13  ||               3  ||             tied  ||  0.8178    ||        96 \n",
      "            12  ||               3  ||             tied  ||  0.8158    ||        90 \n",
      "            20  ||               2  ||             tied  ||  0.8129    ||        92 \n",
      "            20  ||               1  ||             full  ||  0.8129    ||        46 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run mixture model on second binned train set with appended text weights field\n",
    "d = Binarize2(fields_bins,X)\n",
    "bin_train,bin_dev,bin_test = d[0],d[1],d[2]\n",
    "\n",
    "d = Binarize3(bin_train,bin_dev,bin_test)\n",
    "bin_train,bin_dev,bin_test = d[0],d[1],d[2]\n",
    "\n",
    "mixture_model(bin_train,bin_dev,bin_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that maybe splitting out the feature weights into a one binarized field per feature (essentially adding 10 fields) would help create better principle components for the GMM model.  We perform this operation in Binarize4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Binarize4(bin_train,bin_dev,bin_test):\n",
    "    \n",
    "    ###Create binary features for train data\n",
    "    for pos_f in positive_features:\n",
    "        pos_f_arr = []\n",
    "        for line in train_data[:,7]:\n",
    "            pos_f_arr.append(np.where(pos_f[0] in line, 1, 0))\n",
    "        bin_train = np.column_stack((bin_train, pos_f_arr))\n",
    "    for neg_f in negative_features:\n",
    "        neg_f_arr = []\n",
    "        for line in train_data[:,7]:\n",
    "            neg_f_arr.append(np.where(neg_f[0] in line, 1, 0))\n",
    "        bin_train = np.column_stack((bin_train, neg_f_arr))\n",
    "    \n",
    "    ###Create binary features for dev data\n",
    "    for pos_f in positive_features:\n",
    "        pos_f_arr = []\n",
    "        for line in dev_data[:,7]:\n",
    "            pos_f_arr.append(np.where(pos_f[0] in line, 1, 0))\n",
    "        bin_dev = np.column_stack((bin_dev, pos_f_arr))\n",
    "    for neg_f in negative_features:\n",
    "        neg_f_arr = []\n",
    "        for line in dev_data[:,7]:\n",
    "            neg_f_arr.append(np.where(neg_f[0] in line, 1, 0))\n",
    "        bin_dev = np.column_stack((bin_dev, neg_f_arr))\n",
    "    \n",
    "    ###Create binary features for test data\n",
    "    for pos_f in positive_features:\n",
    "        pos_f_arr = []\n",
    "        for line in test_data[:,7]:\n",
    "            pos_f_arr.append(np.where(pos_f[0] in line, 1, 0))\n",
    "        bin_test = np.column_stack((bin_test, pos_f_arr))\n",
    "    for neg_f in negative_features:\n",
    "        neg_f_arr = []\n",
    "        for line in test_data[:,7]:\n",
    "            neg_f_arr.append(np.where(neg_f[0] in line, 1, 0))\n",
    "        bin_test = np.column_stack((bin_test, neg_f_arr))\n",
    "          \n",
    "    return [bin_train,bin_dev,bin_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this new modification didn't improve the accuracy either.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Scoring GMM Models for  Dev Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            11  ||               3  ||             tied  ||  0.8356    ||        84 \n",
      "             9  ||               3  ||             tied  ||  0.8356    ||        72 \n",
      "            13  ||               3  ||             tied  ||  0.8356    ||        96 \n",
      "            10  ||               3  ||             tied  ||  0.8356    ||        78 \n",
      "            12  ||               3  ||             tied  ||  0.8347    ||        90 \n",
      "\n",
      "Top Scoring GMM Models for  Test Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            13  ||               3  ||             tied  ||  0.8149    ||        96 \n",
      "            20  ||               2  ||             full  ||  0.8089    ||        92 \n",
      "            19  ||               2  ||             full  ||  0.8069    ||        88 \n",
      "            17  ||               2  ||             full  ||  0.8069    ||        80 \n",
      "            26  ||               1  ||             full  ||  0.8050    ||        58 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run mixture model on second binned train set with appended binary fields for each text feature\n",
    "d = Binarize2(fields_bins,X)\n",
    "bin_train,bin_dev,bin_test = d[0],d[1],d[2]\n",
    "\n",
    "d = Binarize4(bin_train,bin_dev,bin_test)\n",
    "bin_train,bin_dev,bin_test = d[0],d[1],d[2]\n",
    "\n",
    "mixture_model(bin_train,bin_dev,bin_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the idea to add a calculated field to the dataset, which is simply the character length of the user's message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chars = []\n",
    "for i in X[:,7]:\n",
    "    chars=np.append(chars,int(len(i)))\n",
    "\n",
    "chars=chars.reshape(X.shape[0],1)\n",
    "\n",
    "X=np.column_stack((X,chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then binarize this field as well with the histogram method from Binarize2.  This doesn't appear to improve the accuracy significantly either.  After trying a number of modifications to the data and to our models, it appears we have hit a ceiling in the accuracy we can achieve with GMM models.  While we didn't try everything, the GMM model appears to be our best choice compared with multinomial Naive Bayes or Logistic Regression.  Achieving around ~83% is a relatively good score for this dataset, good for 23rd place out of 464 entrants in the Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Scoring GMM Models for  Dev Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            11  ||               1  ||             full  ||  0.8416    ||        28 \n",
      "            11  ||               1  ||             tied  ||  0.8416    ||        28 \n",
      "            11  ||               2  ||             tied  ||  0.8416    ||        56 \n",
      "            32  ||               1  ||             tied  ||  0.8406    ||        70 \n",
      "            37  ||               1  ||             tied  ||  0.8406    ||        80 \n",
      "\n",
      "Top Scoring GMM Models for  Test Set\n",
      "PCA Components  ||  GMM Components  ||  Covariance Type  ||  Accuracy  ||  Parameters\n",
      "            16  ||               1  ||             tied  ||  0.8248    ||        38 \n",
      "            17  ||               2  ||             tied  ||  0.8248    ||        80 \n",
      "            19  ||               2  ||             tied  ||  0.8248    ||        88 \n",
      "            19  ||               1  ||             tied  ||  0.8248    ||        44 \n",
      "            18  ||               1  ||             tied  ||  0.8248    ||        42 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run mixture model on second binned train set\n",
    "d = Binarize2(fields_bins,X)\n",
    "bin_train,bin_dev,bin_test = d[0],d[1],d[2]\n",
    "mixture_model(bin_train,bin_dev,bin_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
